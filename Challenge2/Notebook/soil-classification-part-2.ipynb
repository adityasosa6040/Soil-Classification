{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":102966,"databundleVersionId":12412856,"sourceType":"competition"},{"sourceId":11891723,"sourceType":"datasetVersion","datasetId":7474485}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/soil-classification-part-2/soil_competition-2025'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-24T17:22:56.184406Z","iopub.execute_input":"2025-05-24T17:22:56.184664Z","iopub.status.idle":"2025-05-24T17:22:58.784593Z","shell.execute_reply.started":"2025-05-24T17:22:56.184645Z","shell.execute_reply":"2025-05-24T17:22:58.783865Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import OneClassSVM\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport torchvision.models as models\n\nfrom sklearn.ensemble import IsolationForest\n\nlabel_map = {\"Alluvial soil\": 0, \"Black Soil\": 1, \"Clay soil\": 2, \"Red soil\": 3}\n\nclass SoilDataset(Dataset):\n    def __init__(self, dataframe, root_dir, transform=None):\n        self.data = dataframe\n        self.root_dir = root_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        img_path = os.path.join(self.root_dir, self.data.iloc[index, 0])\n        image = Image.open(img_path).convert(\"RGB\")\n        label = label_map[self.data.iloc[index, 1]]\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n\ndef resize_and_centercrop224(img):\n        original_width, original_height = img.size\n        target_width, target_height = (224, 224)\n\n        # Calculate aspect ratios\n        original_aspect = original_width / original_height\n        target_aspect = target_width / target_height\n\n        if original_aspect > target_aspect:\n            # Original image is wider than target: Resize based on height\n            new_height = target_height\n            new_width = int(new_height * original_aspect)\n        else:\n            # Original image is taller than target (or same aspect): Resize based on width\n            new_width = target_width\n            new_height = int(new_width / original_aspect)\n\n        # Resize the image\n        img_resized = img.resize((new_width, new_height), Image.Resampling.LANCZOS)\n\n        # Calculate coordinates for centercropping\n        left = (new_width - target_width) / 2\n        top = (new_height - target_height) / 2\n        right = (new_width + target_width) / 2\n        bottom = (new_height + target_height) / 2\n\n        # Crop the image\n        img_cropped = img_resized.crop((left, top, right, bottom))\n\n        return img_cropped\n        \ndef preprocess_images(input_dir, output_dir, size=224):\n    os.makedirs(output_dir, exist_ok=True)\n    for filename in os.listdir(input_dir):\n        img = Image.open(os.path.join(input_dir, filename)).convert(\"RGB\")\n        img = resize_and_centercrop224(img)\n        img.save(os.path.join(output_dir, filename))\n\ndef add_spatial_features(features):\n    \"\"\"\n    Args:\n        features: Tensor of shape [batch, channels, height, width]\n                  (e.g., from ResNet's layer4 output: [64, 512, 7, 7])\n    Returns:\n        Tensor with spatial features added: [batch, channels+2, height, width]\n    \"\"\"\n    batch, channels, height, width = features.shape\n    \n    # Create x/y coordinates (0 to 1 scale)\n    x_coord = torch.linspace(0, 1, width).view(1, 1, -1).repeat(batch, height, 1).to(features.device)\n    y_coord = torch.linspace(0, 1, height).view(1, -1, 1).repeat(batch, width, 1).permute(0,2,1).to(features.device)\n    \n    # Concatenate with original features\n    return torch.cat([\n        features,\n        x_coord.unsqueeze(1),  # Add channel dim\n        y_coord.unsqueeze(1)\n    ], dim=1)\n\n# Preprocess images\npreprocess_images(\"/kaggle/input/soil-classification/soil_classification-2025/train\", \"train_resized\")\n\n# Load dataframe\ndf = pd.read_csv(\"/kaggle/input/soil-classification/soil_classification-2025/train_labels.csv\")\n\n# Initialize ResNet without final layer\nmodel = models.resnet18(pretrained=True)\nmodel = nn.Sequential(*list(model.children())[:-1])  # Remove last FC layeroriginal_\nmodel = nn.DataParallel(model).to(\"cuda\")\nmodel.eval()\n\n# Use all training data for feature extraction\nfull_dataset = SoilDataset(\n    dataframe=df,\n    root_dir=\"train_resized\",\n    transform=transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n    ])\n)\n\ntrain_loader = DataLoader(full_dataset, batch_size=64, shuffle=False, num_workers=8)\n\n# Extract features\nsoil_features = []\nwith torch.no_grad():\n    for images, _ in tqdm(train_loader):\n        images = images.to(\"cuda\")\n        features = model(images).flatten(1)  # [batch_size, 512]\n        soil_features.append(features.cpu().numpy())\n\nsoil_features = np.concatenate(soil_features)\n\n# 4. Train One-Class SVM\nsvm = OneClassSVM(kernel='rbf', gamma='auto', nu=0.05)  # Tune nu parameter\nsvm.fit(soil_features)\n\n# 5. Inference on Test Set\ntest_transform = transforms.Compose([\n    transforms.Resize(224),\n    transforms.CenterCrop(224),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\nsubmission = []\ntest_dir = \"/kaggle/input/soil-classification-part-2/soil_competition-2025/test\"\n\nfor filename in tqdm(sorted(os.listdir(test_dir))):\n    # Load and preprocess\n    img_path = os.path.join(test_dir, filename)\n    img = Image.open(img_path).convert(\"RGB\")\n    img_tensor = test_transform(img).unsqueeze(0).to(\"cuda\")\n    \n    # Extract features\n    with torch.no_grad():\n        features = model(img_tensor).flatten(1).cpu().numpy()\n    \n    # Predict\n    pred = svm.predict(features)[0]\n    label = \"1\" if pred == 1 else \"0\"\n    submission.append((filename, label))\n\n# Save results\npd.DataFrame(submission, columns=[\"image_id\", \"label\"]).to_csv(\"submission.csv\", index=False)\nprint(\"Submission file generated!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T14:06:56.895775Z","iopub.execute_input":"2025-05-25T14:06:56.896490Z","iopub.status.idle":"2025-05-25T14:07:25.479679Z","shell.execute_reply.started":"2025-05-25T14:06:56.896453Z","shell.execute_reply":"2025-05-25T14:07:25.478851Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(\n100%|██████████| 20/20 [00:02<00:00,  8.09it/s]\n100%|██████████| 967/967 [00:11<00:00, 87.26it/s]","output_type":"stream"},{"name":"stdout","text":"Submission file generated!\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":2}]}